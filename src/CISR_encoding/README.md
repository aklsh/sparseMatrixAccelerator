**CISR Encoding**\
CISR encoding is a kind of encoding that reduces the burden on scheduling- typically for runtime scheduling. We encode the sparse matrix in this form offline, and then while loading the data at runtime- it's easy to schedule using this format.
The way it works is as follows:
Let's say we have 'N' slots/ hardware MAC units responsible for doing the multiply and accumulate during sparse Matrix Vector multiply. Now, using this CISR format, one will notice that all the first non-zero elements of each row (until a limit of N rows) is stored in contiguous memory locations. So, all the runtime-scheduler has to do is to fetch the first 'N' values and push it into the MAC units for all slots. 
To explain this in more detail, one can refer to Fig. 2a in the reference paper to get the visuals of CISR encoding:
We can see that the first 4 values(A,C,D,F) ( N = 4 here) are loaded into separate slots. Now, we realize that the 0th, 2nd, 3rd slots are busy because there are multiple values in the same row. The 1st slot is done and ready after encoding 1 value of that row. So, we can assign a new row only for this 1st slot which is free- the 4th row. Meanwhile, the other slots are still busy with 0th, 2nd and 3rd row- which implies that they can take only the consecutive non-zero values on those rows before going to a new un-touched row.
The way it is stored is as shown in fig. 2 c), where the first 4 non-zero values and their col-indices are stored contiguosly, then the next 4 values which each slot can take ( depending on whether it has exhausted all values of the assigned row or not) are stored and so on. 
##### Row length array:
Another point to note here is the 'row_lengths' array, which essentially says the number of non-zero elements in a row assigned to that slow. For eg:- The first four values are the same as the number of non-zero values in the first four rows- because all slots are assigned initially to the first four rows. Now, the 1st slot ( 1st index slot or 2nd slot number) is newly assigned 4th row which has 3 elements which are non-zero (I,J,K) and the position in row length array corresponding to 1st slot says 3. Similarly, the other slots are assigned more rows in the future- (0th slot- 5th row, 2nd slot- 6th row, 3rd- 7th row) and the number of non-zero values in these rows are again updated under the corresponding indices in row len array for the given slots. Please note that row len array doesnt correspond to length of each row in the order presented by the original sparse matrix.
##### CISR Row Index Decoding:
One issue that we have to solve is to figure out how to get the row indices for all encoded values in matrix. As of now, all we have is the number of non-zero elements in a row that each slot can take- in row len array. A good thing here is that whenever multiple slots are freed after completing their rows, new rows are assigned only in the order of increasing channel id ( or slot id). So, now how do we decode the row index?
Firstly, when four values are pushed into 4 channels, we know that now there are multiple mappings happening at once, and the row indices are in the increasing order of the slot ids. So, the values will get row IDs as 0,1,2,3. Global row id will also increment to the last id  = 3. Now, after this, note that other channels are busy- so the row index wont change. Only, 1st slot , which is free gets a new mapping. As of now, only one mapping is happening at this time, so the row index will simply be global row id + 1 ( for the given slot which needs a row). In case there were more slots, then the row indices for them are calculated as global row id + i (slot id).

##### Note:
If a row is completely empty, even that is encoded and stored- this is unavoidable in CISR or CSR as well since it is needed for correct row index calculation.


**References**\
J. Fowers, K. Ovtcharov, K. Strauss, E. S. Chung and G. Stitt, "A High Memory Bandwidth FPGA Accelerator for Sparse Matrix-Vector Multiplication," 2014 IEEE 22nd Annual International Symposium on Field-Programmable Custom Computing Machines, 2014, pp. 36-43, doi: 10.1109/FCCM.2014.23.
